# ğŸ“„ Insurance Policy RAG Chatbot

This project implements a **Retrieval-Augmented Generation (RAG)** based chatbot for **Insurance Policy Question Answering**.  
The chatbot answers user questions **strictly using uploaded insurance policy PDF documents**, without hallucination or external knowledge.

---

## ğŸš€ Features

- ğŸ“š Load and process multiple insurance policy PDFs
- âœ‚ï¸ Chunk documents with overlap for better retrieval
- ğŸ§  Create embeddings using **Ollama (`nomic-embed-text`)**
- ğŸ—‚ Store embeddings in **ChromaDB**
- ğŸ¤– Answer queries using **Groq LLM (`openai/gpt-oss-20b`)**
- âŒ Explicitly refuses to answer if information is not present in documents
- ğŸ§ª Includes test script for ingestion validation

---

## ğŸ“ Project Structure

```

.
â”œâ”€â”€ data/                    # Folder containing insurance PDF files
â”‚   â”œâ”€â”€ policy1.pdf
â”‚   â””â”€â”€ policy2.pdf
â”‚
â”œâ”€â”€ chroma_db/               # Persisted Chroma vector database
â”‚
â”œâ”€â”€ ingest.py                # PDF loading + chunking + vector DB creation
â”œâ”€â”€ chatbot.py               # Interactive RAG-based chatbot
â”œâ”€â”€ requirements.txt         # Python dependencies
â””â”€â”€ README.md                # Project documentation

````

---

## ğŸ›  Tech Stack

- **Python 3.10+**
- **LangChain**
- **ChromaDB**
- **Ollama**
- **Groq LLM**
- **PDFLoader**
- **RecursiveCharacterTextSplitter**

---

## âš™ï¸ Setup Instructions

### 1ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/AsadCodeCraft/PDF_ChatBot_Using_RAG_LLM.git
cd PDF_ChatBot_Using_RAG_LLM
````

---

### 2ï¸âƒ£ Create Virtual Environment (Recommended)

```bash
python -m venv venv
source venv/bin/activate     # Linux / macOS
venv\Scripts\activate        # Windows
```

---

### 3ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

---

### 4ï¸âƒ£ Install & Run Ollama

Download and install Ollama from:
ğŸ‘‰ [https://ollama.com](https://ollama.com)

Pull the required embedding model:

```bash
ollama pull nomic-embed-text
```

Ensure Ollama is running:

```bash
ollama run nomic-embed-text
```

---

## ğŸ“¥ Add Insurance Documents

Place all insurance policy PDFs inside the `data/` folder:

```
data/
â”œâ”€â”€ health_policy.pdf
â”œâ”€â”€ motor_policy.pdf
```

---

## ğŸ§  Create Vector Database

Run the ingestion script:

```bash
python ingest.py
```

âœ… This will:

* Load all PDFs
* Split them into chunks
* Generate embeddings
* Persist them into `chroma_db/`

---

## ğŸ¤– Run the Chatbot

```bash
python chatbot.py
```

Example interaction:

```
ğŸ¤– Insurance Policy Q&A Chatbot
Type 'exit' to quit

You: What is the waiting period for hospitalization?

Answer:
The waiting period for hospitalization is 30 days.

--------------------------------------------------
```

If information is **not found**, the chatbot responds **exactly** with:

```
The provided insurance documents do not contain this information.
```

---


## ğŸ“Œ Design Principles

* âŒ No hallucination
* âŒ No assumptions
* âŒ No external insurance knowledge
* âœ… Answers strictly grounded in document context
* âœ… Deterministic output (`temperature=0`)

---

## ğŸ“ˆ Future Enhancements

* ğŸŒ Web UI (Streamlit / FastAPI)
* ğŸ“Š Source citations per answer
* ğŸ” Metadata filtering
* ğŸ§  Multi-model support
* â˜ï¸ Cloud deployment (Docker)

---

## ğŸ“œ License

MIT License
